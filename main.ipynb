{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import rocket_tools as rt\n",
    "from keras import backend \n",
    "from keras.backend import learning_phase\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, writer_path, sess, model_path, steps=60000, batch_size=32, image_size=128, n_images=3):    \n",
    "    x_input = tf.placeholder(tf.float32, \n",
    "                             [None, image_size, image_size, n_images], \n",
    "                             name='input')\n",
    "    y_true = tf.placeholder(tf.float32, \n",
    "                            [None, image_size, image_size, n_images], \n",
    "                            name='mask_true')\n",
    "    y_pred = model(x_input) \n",
    "    \n",
    "    loss_op = -rt.losses.dice_coef(y_true, y_pred)\n",
    "    adam = tf.train.AdamOptimizer()\n",
    "    train_op = adam.minimize(loss_op)\n",
    "    \n",
    "    with tf.variable_scope('metrics'):\n",
    "        tf.summary.scalar('dice', rt.losses.dice_coef(y_true, y_pred))\n",
    "        tf.summary.scalar('jacard', rt.losses.jacard_coef(y_true, y_pred)) \n",
    "        tf.summary.scalar('accuracy', rt.metrics.accuracy(y_true, y_pred))\n",
    "        tf.summary.scalar('IoU', rt.metrics.IoU(y_true, y_pred))\n",
    "        tf.summary.scalar('log_loss', loss_op)\n",
    "        tf.summary.image('input', x_input[:1, :, :, :1])\n",
    "        tf.summary.image('pred', y_pred[:1, :, :, :1])\n",
    "        tf.summary.image('mask', y_true[:1, :, :, :1])\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        writer = tf.summary.FileWriter(writer_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    image_generator = rt.image_gen.ImageGenerator(image_size=(image_size, image_size))\n",
    "    batch_generator = rt.batch_generator.BatchGenerator(image_generator, batch_size, \n",
    "                                                        snr_mean=5, snr_std=2, n_images=n_images)\n",
    "    \n",
    "    # initialize training session\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "    print('started training')\n",
    "    for step in range(steps):\n",
    "        x, y = next(batch_generator)\n",
    "        _, summary = sess.run([train_op, summary_op], \n",
    "                              feed_dict={\n",
    "                                  x_input: x, \n",
    "                                  y_true: y,\n",
    "                                learning_phase():1\n",
    "                              })\n",
    "        writer.add_summary(summary, step) \n",
    "        \n",
    "    print('finished training')\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started training\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'randit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c17fd6b8ccd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTB_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-44425ae509e5>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, writer_path, sess, model_path, steps, batch_size, image_size, n_images)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'started training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         _, summary = sess.run([train_op, summary_op], \n\u001b[1;32m     40\u001b[0m                               feed_dict={\n",
      "\u001b[0;32m/home/kimsvimpel/Students/sosnovik/u-rocket/rocket_tools/batch_generator.pyc\u001b[0m in \u001b[0;36mBatchGenerator\u001b[0;34m(image_generator, batch_size, snr_mean, snr_std, th_max, n_images)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;31m#noise_max = 200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m#noise = np.random.randint(0, noise_max, size=images.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kimsvimpel/Students/sosnovik/u-rocket/rocket_tools/image_gen.py\u001b[0m in \u001b[0;36mget_images\u001b[0;34m(self, image_size, n_images, sigma_n, mu_n, sigma_snr, mu_snr)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlight_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msnr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'randit'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # parsing\n",
    "    #from argparse import ArgumentParser\n",
    "    #parser = ArgumentParser()\n",
    "\n",
    "    #parser.add_argument('--snr', type=float, required=True)\n",
    "    #options = parser.parse_args()\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "      \n",
    "    image_size = 128\n",
    "    n_images = 3\n",
    "\n",
    "    TB_PATH = './../tensorboard/u_net/image_size={}_snr_all_w'.format(image_size)\n",
    "    MODEL_PATH = './../saved_models/u_net_image_size={}_snr=_all_w'.format(image_size)\n",
    "    os.system('rm -rf {}'.format(TB_PATH))\n",
    "    \n",
    "    model = rt.model.U_NET(input_=(image_size, image_size, n_images))\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    train_model(model, writer_path=TB_PATH, model_path=MODEL_PATH, sess=sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./../saved_models/u_net_image_size=128_snr=_all\n"
     ]
    }
   ],
   "source": [
    "model = rt.model.U_NET(input_=(128, 128, 3))\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, './../saved_models/u_net_image_size=128_snr=_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_input = tf.placeholder(tf.float32, [None, 128, 128, 3], \n",
    "                             name='input')\n",
    "y_pred = model(x_input)\n",
    "pred = y_pred.eval(feed_dict={x_input:-0.5*np.ones([1,128,128,3], dtype='float32'), learning_phase():1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_generator = rt.image_gen.ImageGenerator(image_size=(128, 128))\n",
    "batch_generator = rt.batch_generator.BatchGenerator(image_generator, batch_size=64, snr_mean=5, snr_std=2, n_images=3)\n",
    "\n",
    "x, y =next(batch_generator)\n",
    "pred_s = sess.run(y_pred, feed_dict={x_input: x, learning_phase(): 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 10 22:25:35 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 375.74                 Driver Version: 375.74                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K40c          On   | 0000:03:00.0     Off |                    0 |\r\n",
      "| 23%   42C    P8    22W / 235W |      0MiB / 11439MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla K40c          On   | 0000:04:00.0     Off |                    0 |\r\n",
      "| 30%   62C    P0   119W / 235W |   4605MiB / 11439MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Quadro K4000        On   | 0000:84:00.0      On |                  N/A |\r\n",
      "| 30%   35C    P8    15W /  87W |    202MiB /  3017MiB |      1%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID  Type  Process name                               Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1      4321    C   /usr/bin/python                                350MiB |\r\n",
      "|    1     22998    C   /usr/bin/python                               4251MiB |\r\n",
      "|    2      2392    G   /usr/bin/X                                     102MiB |\r\n",
      "|    2      4587    G   compiz                                          98MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
